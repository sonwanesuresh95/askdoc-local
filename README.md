
# ğŸ§  AskDoc Local - RAG API with FastAPI + Ollama + LangChain

AskDoc Local is a fully offline, API-first Retrieval-Augmented Generation (RAG) system built using:

- ğŸ§© **FastAPI** â€“ For REST APIs  
- ğŸ’¬ **Ollama** â€“ For running lightweight LLMs like `mistral` locally  
- ğŸ”— **LangChain** â€“ For document chunking, embedding, and querying  
- ğŸ“„ **PDF/CSV/XLSX/DOCX** â€“ Multi-format document support  
- ğŸ§  **Chroma (or replaceable)** â€“ Local vector store (swappable with FAISS or Weaviate)  

---

## ğŸ“¦ Features

| Feature | Status |
|--------|--------|
| Upload documents (PDF, CSV, XLSX, DOCX) | âœ… |
| Parse and chunk text using LangChain | âœ… |
| Embed using Ollama models (e.g., mistral) | âœ… |
| Store embeddings locally in ChromaDB | âœ… |
| Ask questions via `/query/` API | âœ… |
| Delete single or all documents | âœ… |
| Debug API to inspect indexed documents | âœ… |
| Reset API to wipe everything clean | âœ… |

---

## ğŸš€ Quick Start

### 1. Clone & Install

```bash
git clone https://github.com/sonwanesuresh95/askdoc-local.git
cd askdoc-local
pip install -r requirements.txt
```

### 2. Start Ollama

```bash
ollama run mistral
```

Make sure Ollama is running and the model is pulled.

### 3. Start the API server

```bash
uvicorn app.main:app --reload
```

---

## ğŸ› ï¸ API Endpoints

### ğŸ“„ Upload Document

```http
POST /upload/
Content-Type: multipart/form-data
```

Upload `.pdf`, `.docx`, `.csv`, or `.xlsx`. The document is parsed, chunked, embedded, and stored.

---

### â“ Ask a Question

```http
POST /query/
{
  "query": "What is Acme Corp's revenue?"
}
```

Returns an answer based on uploaded and embedded documents.

---

### ğŸ—‘ï¸ Delete a Document

```http
DELETE /api/documents/{doc_id}
```

Deletes uploaded file, parsed `.txt`, and embeddings.

---

### ğŸ”„ Reset Entire System

```http
POST /reset/
```

Deletes all uploaded files, parsed text, and vector DB.

---

### ğŸ Debug Vector Store

```http
GET /debug/vectorstore
```

Returns a list of indexed documents and their chunk counts.

---

## ğŸ“ Directory Structure

```
askdoc-local/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ services/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ documents/         # Uploaded files
â”‚   â”œâ”€â”€ parsed_text/       # Parsed .txt files
â”‚   â”œâ”€â”€ vector_store/      # Chroma DB data
â”‚   â””â”€â”€ document_index.json
```

---

## ğŸ§  Embedding Model

- Uses `OllamaEmbeddings(model="mistral")` from `langchain_ollama`
- You can replace with any local model supported by Ollama (e.g., `llama2`, `codellama`, `phi`)

---

## ğŸ”„ Future Plans

- [ ] Frontend UI using React + Material UI  
- [ ] Weaviate-based vector backend  
- [ ] Docker + CI/CD setup  
- [ ] Streamlit Playground UI

---

## ğŸ§‘â€ğŸ’» Author

**Suresh Sonwane**  
GitHub: [@sonwanesuresh95](https://github.com/sonwanesuresh95)

---

## ğŸ“œ License

MIT License
